\section{Data Acquisition and Preprocessing}
The selection and subsequent preprocessing of the dataset are crucial steps in the development of our recommendation system. This chapter provides a detailed examination of the chosen data.

\subsection{Dataset}
The MovieLens dataset , which is publicly accessible and provided by GroupLens, was utilized in this project. The dataset contains user ratings and a wide collection of user-generated tags from the IMDb dataset. Its relationship with IMDb's comprehensive movie metadata makes it a particularly suitable choice for our project. 

The tags and their relevance to each movie represent different characteristics of them, such as genre, themes and narrative devices, among other categorical and descriptive identifiers.
% Given the These tags, generated by users, are a significant feature for our movie recommendation model, given their expressiveness and depth of information.

The main dataset to be used for the characterisation of each movie consists of three columns: movieId, tagId and relevance. 

For both the movieId and tagId values, there is a respective reference file connecting the Ids to the movie titles and tag strings.

\begin{verbatim}
==> ./ml-25m/genome-scores.csv <==
movieId,tagId,relevance
1,1,0.028749999999999998
1,2,0.023749999999999993
1,3,0.0625
1,4,0.07574999999999998
...

==> ./ml-25m/genome-tags.csv <==
tagId,tag
1,007
2,007 (series)
3,18th century
4,1920s
...

==> ./ml-25m/movies.csv <==
movieId,title,genres
1,Toy Story (1995),Adventure|Animation|Chi...
2,Jumanji (1995),Adventure|Children|Fanta...
3,Grumpier Old Men (1995),Comedy|Romance
4,Waiting to Exhale (1995),Comedy|Drama|Ro...
...
\end{verbatim}

The relevance values of the movies stem from the tags given by the users, which can be found as part of the dataset in the following form:

\begin{verbatim}
==> ./ml-25m/tags.csv <==
userId,movieId,tag,timestamp
3,260,classic,1439472355
3,260,sci-fi,1439472256
4,1732,dark comedy,1573943598
4,1732,great dialogue,1573943604
\end{verbatim}

% The dataset consists of four primary columns: userId, movieId, rating, and timestamp.


% Contains user-generated tags describing various aspects of the movie, including its genre, themes, narrative elements, and other categorical identifiers


% An example of a data line regarding the user tags in the IMDb dataset is structured as follows:

% \begin{verbatim}
% userId,movieId,tag,timestamp
% 2,60756,funny,1445714994
% 2,60756,Highly quotable,1445714996
% 2,60756,will ferrell,1445714992
% 2,89774,Boxing story,1445715207
% 2,89774,MMA,1445715200
% \end{verbatim}

For the characterization of the individual users, the utilized data consisted of four columns: userId, movieId, rating, and timestamp.

\begin{itemize}
\item \texttt{userId}: Represents the unique identifier for each user.
\item \texttt{movieId}: Denotes the unique identifier for each movie in the IMDb database.
\item \texttt{rating}: Personal rating given by the user for the Movie.
\item \texttt{timestamp}: Indicates the time (in UNIX timestamp format) at which the user tagged the movie.
\end{itemize}

\begin{verbatim}
==> ./ml-25m/ratings.csv <==
userId,movieId,rating,timestamp
2,60756,funny,1445714994
2,60756,Highly quotable,1445714996
2,60756,will ferrell,1445714992
2,89774,Boxing story,1445715207
2,89774,MMA,1445715200
\end{verbatim}

This data extract shows user 2 tagging two movies (with IDs 60756 and 89774) with various tags, with each tagging action being logged with a corresponding timestamp.\\

An essential aspect to consider within the context of our project is the inherent variability of user-generated tags in the dataset. These tags are not uniformly distributed and, more critically, they exhibit considerable inconsistency and redundancy. For instance, a user might tag a film with the word "zombi," while another might use "zombie," and yet another might use "zomby" - all intending to signify the same concept. This variation could extend beyond spelling inconsistencies to include differences in phrasing, abbreviations, semantics, and language use.

% The diverse interpretations and representations of essentially similar tags pose a considerable challenge. If not addressed, they can introduce noise and redundancy into the dataset, adversely impacting the performance of our recommendation model. Hence, the necessity for preprocessing becomes apparent, with the aim to standardize and consolidate the tags, reducing the feature size and complexity.

% The upcoming sections will elaborate on the methods employed for data preprocessing, particularly addressing our approach to the task of feature reduction within this high-dimensional dataset.


\subsection{Feature Reduction through Preprocessing}

The high dimensionality of the dataset, particularly the user tags, presents a significant challenge. The sheer number of tags (1128) is a considerable obstacle to the development of a recommendation system. The tags are also highly variable, with a large number of them being redundant or irrelevant. This variability is a significant source of noise, which can adversely impact the performance of our recommendation model. Hence, the necessity for preprocessing becomes apparent, with the aim to standardize and consolidate the tags, reducing the feature size and complexity.

The ability to distill this data into a format that is reduced but still retains its meaningful information is crucial for the complexity and performance of a recommendation model.
%  This subsection presents a detailed walkthrough of our data preprocessing steps, focusing on our approach to significantly reducing the feature size from the original tag space.\\

\noindent The Python script we utilized for data preprocessing follows this approach:

\begin{enumerate}
    \item \textbf{Loading data:} We start by loading multiple CSV files from the ML dataset using the pandas library. We create dictionaries to map identifiers to their respective tags and movie titles, thereby preparing our data for the subsequent preprocessing steps.
    \item \textbf{Identifying relevant tags:} To reduce dimensionality and retain the most valuable information, we first isolate 'relevant' tags based on a mean relevance threshold. Tags, whose mean relevance across all movies exceeds this threshold, are considered 'relevant' for our analysis. This operation significantly reduces the tag count, allowing us to focus on the most indicative tags.
    \item \textbf{Finding synonyms:} After extracting relevant tags, we further explore correlations among these tags to identify potential synonyms â€” tags that essentially signify the same concept. We compute the correlation matrix and identify highly correlated tag pairs, which we consider as synonyms. This step again contributes to the reduction in feature size.
    \item \textbf{Replacing synonyms:} In the final step, we replace the synonyms identified in the previous step with a single representative tag. We choose the most relevant tag from each group of synonyms as the representative tag. The representative tag will then assume the maximum value among the synonymous tags for each movie, and the synonymous tags are dropped from the dataset. This operation further reduces the dimensionality of our tag space.
\end{enumerate}

After preprocessing, the data is significantly reduced in dimensionality, while retaining meaningful tags for analysis. Some representative examples of the processed tag groups are as follows:

\begin{small}
\begin{verbatim}
["greed", "corruption", "morality"]
["satirical", "satire", "sarcasm", "irreverent"]
["crude humor", "hilarious", "stupid", "funny"]
["divorce", "marriage", "infidelity"]
\end{verbatim}
\end{small}

Each array denotes a synonym group of tags that have been discerned and summarized through the preprocessing steps. The tags grouped within a single array were established as synonyms via correlation analysis, indicative of analogous thematic undertones. Taking the first array as an example, the tags "greed," "corruption," and "morality" all encapsulate the primary themes of the associated film. This reduction in tag representation, through synonym identification, substantially lowers the dimensionality of the input space, contributing to a more efficient implementation of the k-means clustering algorithm. 

In the finalized format of our dataset, the primary components consist of film titles and their corresponding tag group relevances. The film titles function as unique identifiers in the y-axis, effectively representing individual data points. In parallel, the x-axis is composed of the tag relevances resulting from our preprocessing steps. This matrix of film titles and their tag relevances are the input for the k-means clustering algorithm. This data arrangement allows the algorithm to observe patterns in tag relevances across different movies, and accordingly, cluster films that exhibit similar thematic elements. 

